---
title: "Week 8"
author: "Nikhil Desai"
date: "`r Sys.Date()`"
output: html_document
---

# Classification II

This week we continued to study classification of earth observation data, focussing on the distinction between object-based and pixel-based classification. Secondly, we look at how we can assess the accuracy of our classification results. 

First, I will provide an overview, including the strengths weaknesses and common applications of object based image classification and pixel based image classification (Superpixel and Subpixel), then dive into some methods of how to assess the accuracy of our classification results. When comparing the two methods, they can almost be seen as *opposite* approaches.

### **Pixel-Based Image Analysis**:

In pixel-based image analysis, each pixel is analysed and classified independently based on its spectral signature. This method includes sub-pixel analysis, which estimates the fractional coverage of different land cover types within a single pixel.

**Strengths:** Offers high precision in identifying land cover types within mixed pixels, ideal for fine-scale analysis. 
**Weaknesses:** Complexity in selecting appropriate endmembers and challenges in accuracy assessment. 
**Common Uses:** Widely used in agricultural monitoring, where detailed differentiation between crop types and growth stages within a single pixel is critical. Includes spectral unmixing as a sub-method.

```{r echo=FALSE, out.width="70%", fig.cap="Superpixel Analysis - [Liu et al., 2022](https://www.mdpi.com/2072-4292/14/4/899)"}
knitr::include_graphics("img/subpixelanalysis.png")
```

The second method is superpixel analysis. This method groups similar pixels into larger *superpixels* for more efficient processing and analysis, maintaining the granularity of pixel-level detail but reducing computational complexity. Super

**Strengths:** Simplifies the image by reducing the number of individual elements to be analysed, making it easier to manage and classify large datasets. 
**Weaknesses:** The choice of parameters for clustering can greatly affect the outcome, and inappropriate settings may lead to over- or under-segmentation. 
**Common Uses:** Useful in large-scale land cover mapping and environmental monitoring where delineating homogeneous areas (like forest stands) is necessary. K-means clustering and Simple Non-Iterative Clustering (SNIC) are sub-methods that aid in creating super-pixels.

```{r echo=FALSE, out.width="70%", fig.cap="Subpixel Analysis - [Mclachlan et al., 2017](https://www.tandfonline.com/doi/pdf/10.1080/01431161.2017.1346403?needAccess=true&)"}
knitr::include_graphics("img/superpixelanalysis.webp")
```

**Object-Based Image Analysis (OBIA)**: OBIA groups adjacent pixels into *objects* based on their spectral characteristics. This approach considers the context and texture of features within an image, allowing for more nuanced analysis and classification based on the properties of these objects, rather than individual pixels.

**Strengths:** Effective in handling spatial patterns and relationships between objects, reducing the 'salt and pepper' noise common in pixel-based classifications. **Weaknesses:** Can be computationally intensive and requires careful parameter tuning for segmenting images into meaningful objects. **Common Uses:** Primarily used in urban planning, forest mapping, and habitat delineation, where the spatial arrangement and context of objects (like buildings or vegetation patches) are important. Techniques like image gradient and spectral gradient analysis are sub-methods within OBIA.

```{r echo=FALSE, results='asis'}
cat(
  '<div style="margin-bottom: 40px;">',
  '<img src="', knitr::image_uri("img/OBIA1.png"), '" style="width: 49%; float: left; margin-right: 2%;" />',
  '<img src="', knitr::image_uri("img/OBIA2.jpeg"), '" style="width: 45.5%; float: right;" />',
  '</div>',
  '<div style="clear: both;"></div>'
)
```

Source: [Kate Alison, 2023](https://www.udemy.com/course/object-based-image-analysis-classification-in-qgisarcgis/) and [GIS Geography, 2024](https://gisgeography.com/obia-object-based-image-analysis-geobia/)

## Accuracy Assessment of Classification

Accuracy assessments for classification results evaluate how well the classification method has performed by comparing the classified data with reference data (*ground truth* or *true* values).

#### Key Methods Used

-   Confusion Matrix (Error Matrix): A powerful tool that cross-tabulates the actual categories (from ground truth) against the classified categories. It provides metrics like overall accuracy, user’s and producer’s accuracy, and Kappa coefficient.

-   Producer’s and User’s Accuracy: These metrics derive from the confusion matrix. Producer's accuracy measures the probability that a ground-truth pixel is correctly classified, while user's accuracy shows the probability that a pixel classified into a category actually represents that category on the ground.

-   F-1 Score:  The harmonic mean of user’s accuracy and producer’s accuracy for a class. It balances both measures and gives a single value that balances both.

$$F1 = \frac{2 \times \text{TP}}{2 \times \text{TP} + \text{FP} + \text{FN}}$$

#### Importance of Conducting Accuracy Assessments

-   Validation of Results: Accuracy assessment validates the classification results, ensuring they are reliable for decision-making or further analysis.

*Benchmarking and Comparison: It allows for the comparison of different classification algorithms or methods, helping to select the most suitable one for a specific application.

-   Identifying Errors: Helps in identifying specific classes or areas where classification errors are more common, guiding improvements in the classification process.

#### Potential Pitfalls

-   Inadequate Reference Data: The quality and quantity of ground truth data can significantly affect the accuracy assessment. Insufficient or inaccurate reference data may lead to misleading assessment results.

-   Spatial and Temporal Mismatches: Differences in the timing of satellite imagery and the collection of reference data can introduce errors due to changes in the landscape or land use.

-   Class Ambiguity: In cases where classes are spectrally similar or the land cover is heterogeneous, distinguishing between classes becomes difficult, potentially leading to lower accuracy.

-   Overfitting: Especially in machine learning classifiers, there's a risk of overfitting the model to the training data, which can result in high accuracy for the training dataset but poor generalization to new, unseen data.

## Applications

I've mentioned several applications of classifications and sources in my description above. So, in this *application* section instead of discussing case studies, I was keen to do some brainstorming of how classification could be used to help solve a problem close to me. I did not find any prior research on this topic, so I thought it would be interesting to brainstorm an approach this week.

I spent several summers tree-planting in western Canada as part of forest regeneration efforts. I was employed by logging companies who, by law, must replant all tress they cut down. I was rather disillusioned by this, as there was no logic to the selection of trees being replanted or any concern about the original biodiversity of the forest. Trees were planted for the sake of it with no intention of restoring the forest to its original state.

```{r echo=FALSE, out.width="70%", fig.cap="Subpixel Analysis - [European Commission, 2024](https://environment.ec.europa.eu/news/birds-eye-view-boreal-forests-using-satellite-remote-sensing-monitor-biodiversity-richness-2023-10-04_en)"}
knitr::include_graphics("img/biodiversity.jpg")
```

Here, I see an opportunity for subpixel analysis to enhance forest management, particularly in assessing reforestation efforts after clear cutting. This would be an exercise in change detection, comparing biodiversity levels before logging occurs in an area and after tree planting efforts. The goal would be to ensure that the replanted trees are not only surviving but also contributing to the restoration of the original biodivrsity of the ecosystem.

Subpixel analysis would allow for a detailed examination of satellite imagery to detect changes in forest biodiversity and density at a finer resolution than what is visible at the pixel level. This could identify the health of newly planted trees within each pixel, even if they occupy only a part of it, providing a nuanced view of regeneration efforts over time.

Personally, I would first apply spectral unmixing to Landsat data. I believe this could isolate the spectral signatures of different vegetation types. This process involves identifying "endmembers," which are the pure spectral signatures of specific land cover types, including various tree species indicative of the region's original biodiversity. By assessing how these signatures mix at pixel level, we can estimate the proportions of each vegetation type at the subpixel level, effectively monitoring the progress of reforestation and the restoration of biodiversity over time.

However, the challenge lies in validating the results of subpixel analysis. And this is where I believe an accuracy assessment would help

One approach is to harden the subpixel data by converting the fractional coverage of each vegetation type into discrete classification, where pixels are assigned to the land cover type that occupies the majority of their area. This hardened classification can then be compared against high-resolution aerial or drone imagery, serving as ground truth.

## Reflections

This week's topic was quite challenging, as it required a deep dive into remote sensing classification techniques and accuracy assessments. It was very interesting to learn some techniques to add conviction and certainty to remote sensing analysis. Over the past weeks we have raced through a wide array of theory and many techniques, it was useful to learn about some techniques which can help us check the accuracy of our results and help to determine whether our choice of classification method was appropriate.

Doing a bit of brainstorming on how these techniques could be applied to a real-world problem was interesting exercise. In week 4 we were tasked to something similar, however after 4 weeks of learning about methods and technical details, I was able to develop a more specific and detailed idea of how these techniques could be applied to a problem close to me.